{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd models/bert\n",
    "# !gdown 1nxVBajc4_thMTXOWdxstQnyzJ6SiqV8J  # 기본 KoBERT\n",
    "\n",
    "# %cd models/poly_encoder\n",
    "# !gdown 1VtB3fYNVb7I1dIIB4PuYVJpvQatePsLz  # 우리가 학습시킨 모델\n",
    "\n",
    "# %cd models/cross_encoder\n",
    "# !gdown 1-5Uei2q3uqbSPyMXzoSIj50l7dxIL2Kh  # 우리가 학습시킨 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd  # Poly-Enocder folder로 가도록\n",
    "from utils.model_for_inference import Load_Model_Tokenizer\n",
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "\n",
    "CATEGORY = '' # normal, water, corona\n",
    "\n",
    "poly_dir = 'path/to/poly_encoder'\n",
    "cross_dir = 'path/to/cross_encoder'\n",
    "emb_dir = 'datasets'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# q1, q2, q3, q4, text, embedding(text에 대한) 저장 pickle / 하지만 현재는 inference에 text와 embedding만 사용\n",
    "with open(os.path.join(emb_dir, f'{CATEGORY}_with_text.pickle'), 'rb') as f:     \n",
    "    embedding_df = pickle.load(f)\n",
    "\n",
    "cross_encoder, _ = Load_Model_Tokenizer(cross_dir, model_type='cross')\n",
    "poly_encoder, tokenizer = Load_Model_Tokenizer(poly_dir, model_type='poly')\n",
    "cross_encoder.to(device)\n",
    "poly_encoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.inference import Callcenter\n",
    "import numpy as np \n",
    "\n",
    "call_center = Callcenter(poly_encoder=poly_encoder, cross_encoder=cross_encoder,\n",
    "                        tokenizer=tokenizer, emb_df=embedding_df, device=device, topk=5)\n",
    "\n",
    "query = '집에 가고 싶다.'\n",
    "top_k_cross_scores, top_k_indices= call_center.inference(query)\n",
    "# poly score가 가장 높은 k개의 답변 값들의 cross score 값과 index들 반환\n",
    "\n",
    "top_cross_idx = top_k_indices[np.argmax(top_k_cross_scores)]\n",
    "# k개의 답변들 중 cross score가 가장 높은 idx이용하여 최종 답변 산출\n",
    "answer = embedding_df['text'].iloc[top_cross_idx]\n",
    "\n",
    "print(f'질문 : {query}')\n",
    "print(f'답변 : {answer}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
