{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import os \n",
    "import glob \n",
    "import cv2 \n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from moviepy.video.io.VideoFileClip import VideoFileClip\n",
    "from moviepy.editor import VideoFileClip, AudioFileClip, concatenate_videoclips\n",
    "import tarfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install moviepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python.exe -m pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ffmpeg in d:\\alpaco\\vscode\\testenv\\lib\\site-packages (1.4)\n"
     ]
    }
   ],
   "source": [
    "# !pip install ffmpeg --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: decorator==4.4.2 in d:\\alpaco\\vscode\\testenv\\lib\\site-packages (4.4.2)\n"
     ]
    }
   ],
   "source": [
    "# !pip install --upgrade decorator==4.4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "# !pip uninstall moviepy decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_frame_dataset(json_path):  # return : (start_frame, end_frame, 말한 문장)\n",
    "    with open(json_path, 'rb') as f: \n",
    "        data = json.load(f)\n",
    "\n",
    "    fps = 25\n",
    "\n",
    "    frame_datas = []\n",
    "    sentence_infos = data[0].get('Sentence_info')\n",
    "    for voice in sentence_infos:\n",
    "        start_frame = int(voice['start_time']*fps)\n",
    "        end_frame = int(voice['end_time']*fps)\n",
    "        sentence_text = voice['sentence_text']\n",
    "        frame_datas.append((start_frame, end_frame, sentence_text))\n",
    "    return frame_datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fps_29_to_25(video_path, fps=25): \n",
    "    video = VideoFileClip(video_path)\n",
    "    video = video.set_fps(fps)\n",
    "    # 변경된 속도로 비디오 파일 저장\n",
    "    video.write_videofile(video_path.split('.')[0]+'_25fps.mp4', fps=fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_video_audio(video_path, start, end, video_save_path, audio_save_path):\n",
    "    cap = cv2.VideoCapture(video_path)  # 영상용\n",
    "    start -=15\n",
    "    end += 15\n",
    "    \n",
    "    # 프레임 속성 알아내기\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, start)  \n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(video_save_path, fourcc, fps, (1080, 720))         # 여기서 512 로 맞춰줬음\n",
    "\n",
    "    # 지정된 프레임 추출 및 저장\n",
    "    for i in tqdm(range(end-start)):   \n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            resized_frame = cv2.resize(frame, (int(frame_width//1.5), int(frame_height//1.5)))          # frame_width//2.109도 512에 맞춘거라 바꾸려면 바꿔야함 \n",
    "            crop_frame = resized_frame[:,100:1180]\n",
    "            out.write(crop_frame)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    # 비디오 파일 닫기\n",
    "    cap.release()\n",
    "    out.release()\n",
    "\n",
    "    # 비디오 파일 열기\n",
    "    video = VideoFileClip(video_path)       # 비디오용\n",
    "\n",
    "    # 프레임 범위에 해당하는 프레임 추출\n",
    "    frames = video.subclip(start/video.fps, end/video.fps)\n",
    "    # 추출한 프레임에 해당하는 오디오 데이터 추출\n",
    "    sub_audio = frames.audio\n",
    "    # 추출한 프레임과 오디오를 함께 저장\n",
    "    sub_audio.write_audiofile(audio_save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_vid_aud(vid_path, aud_path, out_path):\n",
    "    # 비디오와 오디오 파일 열기\n",
    "    video_clip = VideoFileClip(vid_path)\n",
    "    audio_clip = AudioFileClip(aud_path)\n",
    "\n",
    "    # 오디오와 비디오를 합치기\n",
    "    final_clip = video_clip.set_audio(audio_clip)\n",
    "\n",
    "    # 최종 파일로 내보내기\n",
    "    final_clip.write_videofile(out_path, verbose=False, logger=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_Atypevideo_from_tar(tar_path, ex_path):\n",
    "    with tarfile.open(tar_path, 'r') as tar: \n",
    "        video_names = tar.getmembers()\n",
    "        for i in tqdm(video_names): \n",
    "            file_name = i.name\n",
    "            if file_name.endswith('A_001.mp4') or file_name.endswith('C_002.mp4') or file_name.endswith('E_003.mp4') or file_name.endswith('G_004.mp4') or file_name.endswith('I_005.mp4') :\n",
    "                tar.extract(tar.getmember(file_name), ex_path)\n",
    "                os.rename(os.path.join(ex_path, file_name), os.path.join(ex_path, file_name.split('/')[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_Atypejson_from_tar(tar_path, ex_path):\n",
    "    with tarfile.open(tar_path, 'r') as tar: \n",
    "        json_names = tar.getmembers()\n",
    "        for i in tqdm(json_names): \n",
    "            file_name = i.name\n",
    "            if file_name.endswith('A_001.json') or file_name.endswith('C_002.json') or file_name.endswith('E_003.json') or file_name.endswith('G_004.json') or file_name.endswith('I_005.json'):\n",
    "                tar.extract(tar.getmember(file_name), ex_path)\n",
    "                os.rename(os.path.join(ex_path, file_name), os.path.join(ex_path, file_name.split('/')[-1]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Tar 파일에서 A타입 mp4 파일만 뽑아내기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\\n"
     ]
    }
   ],
   "source": [
    "%cd E:\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_path = r'E:\\dataset\\source'   # 필요한 원본 파일들만 뽑아서 저장할 경로\n",
    "if not os.path.exists(ex_path):\n",
    "    os.makedirs(ex_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1, 53, 54, 55, 56, 57"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'E:\\\\009.립리딩(입모양) 음성인식 데이터\\\\01.데이터\\\\1.Training\\\\원천데이터\\\\TS2.tar'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m VIDEO_FOLDER \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mTS\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39mTAR_NUM    \u001b[39m# 원천 데이터 tar파일 이름\u001b[39;00m\n\u001b[0;32m      3\u001b[0m VIDEO_PATH \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mE:\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39m009.립리딩(입모양) 음성인식 데이터\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39m01.데이터\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39m1.Training\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39m원천데이터\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39mVIDEO_FOLDER\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.tar\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m----> 4\u001b[0m extract_Atypevideo_from_tar(VIDEO_PATH, ex_path)\n\u001b[0;32m      5\u001b[0m \u001b[39m# 원본 라벨 tar파일에서 필요한(A방향) json만 뽑기\u001b[39;00m\n\u001b[0;32m      6\u001b[0m JSON_FOLDER \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mTL\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39mTAR_NUM     \u001b[39m# 라벨링 데이터 tar파일 이름\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m, in \u001b[0;36mextract_Atypevideo_from_tar\u001b[1;34m(tar_path, ex_path)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mextract_Atypevideo_from_tar\u001b[39m(tar_path, ex_path):\n\u001b[1;32m----> 2\u001b[0m     \u001b[39mwith\u001b[39;00m tarfile\u001b[39m.\u001b[39;49mopen(tar_path, \u001b[39m'\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m tar: \n\u001b[0;32m      3\u001b[0m         video_names \u001b[39m=\u001b[39m tar\u001b[39m.\u001b[39mgetmembers()\n\u001b[0;32m      4\u001b[0m         \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m tqdm(video_names): \n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\tarfile.py:1632\u001b[0m, in \u001b[0;36mTarFile.open\u001b[1;34m(cls, name, mode, fileobj, bufsize, **kwargs)\u001b[0m\n\u001b[0;32m   1630\u001b[0m     saved_pos \u001b[39m=\u001b[39m fileobj\u001b[39m.\u001b[39mtell()\n\u001b[0;32m   1631\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1632\u001b[0m     \u001b[39mreturn\u001b[39;00m func(name, \u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m, fileobj, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1633\u001b[0m \u001b[39mexcept\u001b[39;00m (ReadError, CompressionError) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   1634\u001b[0m     error_msgs\u001b[39m.\u001b[39mappend(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m- method \u001b[39m\u001b[39m{\u001b[39;00mcomptype\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m!r}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\tarfile.py:1698\u001b[0m, in \u001b[0;36mTarFile.gzopen\u001b[1;34m(cls, name, mode, fileobj, compresslevel, **kwargs)\u001b[0m\n\u001b[0;32m   1695\u001b[0m     \u001b[39mraise\u001b[39;00m CompressionError(\u001b[39m\"\u001b[39m\u001b[39mgzip module is not available\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m   1697\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1698\u001b[0m     fileobj \u001b[39m=\u001b[39m GzipFile(name, mode \u001b[39m+\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mb\u001b[39;49m\u001b[39m\"\u001b[39;49m, compresslevel, fileobj)\n\u001b[0;32m   1699\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   1700\u001b[0m     \u001b[39mif\u001b[39;00m fileobj \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\gzip.py:174\u001b[0m, in \u001b[0;36mGzipFile.__init__\u001b[1;34m(self, filename, mode, compresslevel, fileobj, mtime)\u001b[0m\n\u001b[0;32m    172\u001b[0m     mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    173\u001b[0m \u001b[39mif\u001b[39;00m fileobj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 174\u001b[0m     fileobj \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmyfileobj \u001b[39m=\u001b[39m builtins\u001b[39m.\u001b[39;49mopen(filename, mode \u001b[39mor\u001b[39;49;00m \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m    175\u001b[0m \u001b[39mif\u001b[39;00m filename \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    176\u001b[0m     filename \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(fileobj, \u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'E:\\\\009.립리딩(입모양) 음성인식 데이터\\\\01.데이터\\\\1.Training\\\\원천데이터\\\\TS2.tar'"
     ]
    }
   ],
   "source": [
    "for TAR_NUM in [str(i) for i in range(2, 14)]: \n",
    "    VIDEO_FOLDER = 'TS'+TAR_NUM    # 원천 데이터 tar파일 이름\n",
    "    VIDEO_PATH = 'E:\\\\009.립리딩(입모양) 음성인식 데이터\\\\01.데이터\\\\1.Training\\\\원천데이터\\\\'+VIDEO_FOLDER+'.tar'\n",
    "    extract_Atypevideo_from_tar(VIDEO_PATH, ex_path)\n",
    "    # 원본 라벨 tar파일에서 필요한(A방향) json만 뽑기\n",
    "    JSON_FOLDER = 'TL'+TAR_NUM     # 라벨링 데이터 tar파일 이름\n",
    "    JSON_PATH = 'E:\\\\009.립리딩(입모양) 음성인식 데이터\\\\01.데이터\\\\1.Training\\\\라벨링데이터\\\\'+JSON_FOLDER+'.tar'\n",
    "    extract_Atypejson_from_tar(JSON_PATH, ex_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAR_NUM = '53'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "350d5b6332ea4088bede01a2a527c5d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/293 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 원본 비디오 tar파일에서 필요한(A방향) 비디오만 뽑기\n",
    "VIDEO_FOLDER = 'TS'+TAR_NUM    # 원천 데이터 tar파일 이름\n",
    "VIDEO_PATH = 'E:\\\\009.립리딩(입모양) 음성인식 데이터\\\\01.데이터\\\\1.Training\\\\원천데이터\\\\'+VIDEO_FOLDER+'.tar'\n",
    "extract_Atypevideo_from_tar(VIDEO_PATH, ex_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7d817e44fbc44c0b33d50082045f3ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/245 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 원본 라벨 tar파일에서 필요한(A방향) json만 뽑기\n",
    "JSON_FOLDER = 'TL'+TAR_NUM     # 라벨링 데이터 tar파일 이름\n",
    "JSON_PATH = 'E:\\\\009.립리딩(입모양) 음성인식 데이터\\\\01.데이터\\\\1.Training\\\\라벨링데이터\\\\'+JSON_FOLDER+'.tar'\n",
    "extract_Atypejson_from_tar(JSON_PATH, ex_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 전처리(resize, 발화별 자르기) 후 비디오, 오디오 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_path = 'E:\\\\alpaco\\\\data\\\\AI_hub'  \n",
    "video_paths = sorted([os.path.join(ex_path, i) for i in  glob.glob1(ex_path, '*.mp4') if not i.endswith('fps.mp4')])    # 비디오 파일과 json 파일들 저장되어 있는 경로들\n",
    "json_paths = sorted([os.path.join(ex_path, i) for i in  glob.glob1(ex_path, '*.json')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195 195\n"
     ]
    }
   ],
   "source": [
    "print(len(video_paths), len(json_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['E:\\\\alpaco\\\\data\\\\AI_hub\\\\lip_J_1_F_04_C190_A_012.json',\n",
       " 'E:\\\\alpaco\\\\data\\\\AI_hub\\\\lip_J_1_F_04_C190_C_005.json',\n",
       " 'E:\\\\alpaco\\\\data\\\\AI_hub\\\\lip_J_1_F_04_C190_G_006.json',\n",
       " 'E:\\\\alpaco\\\\data\\\\AI_hub\\\\lip_J_1_F_04_C210_A_010.json',\n",
       " 'E:\\\\alpaco\\\\data\\\\AI_hub\\\\lip_J_1_F_04_C210_C_003.json',\n",
       " 'E:\\\\alpaco\\\\data\\\\AI_hub\\\\lip_J_1_F_04_C210_G_001.json',\n",
       " 'E:\\\\alpaco\\\\data\\\\AI_hub\\\\lip_J_1_F_04_C235_A_011.json',\n",
       " 'E:\\\\alpaco\\\\data\\\\AI_hub\\\\lip_J_1_F_04_C235_C_004.json',\n",
       " 'E:\\\\alpaco\\\\data\\\\AI_hub\\\\lip_J_1_F_04_C235_G_002.json',\n",
       " 'E:\\\\alpaco\\\\data\\\\AI_hub\\\\lip_J_1_F_04_C245_A_009.json',\n",
       " 'E:\\\\alpaco\\\\data\\\\AI_hub\\\\lip_J_1_F_04_C245_C_005.json',\n",
       " 'E:\\\\alpaco\\\\data\\\\AI_hub\\\\lip_J_1_F_04_C245_G_006.json',\n",
       " 'E:\\\\alpaco\\\\data\\\\AI_hub\\\\lip_J_1_F_04_C253_A_008.json',\n",
       " 'E:\\\\alpaco\\\\data\\\\AI_hub\\\\lip_J_1_F_04_C253_C_004.json',\n",
       " 'E:\\\\alpaco\\\\data\\\\AI_hub\\\\lip_J_1_F_04_C253_G_003.json',\n",
       " 'E:\\\\alpaco\\\\data\\\\AI_hub\\\\lip_J_1_F_04_C254_A_003.json',\n",
       " 'E:\\\\alpaco\\\\data\\\\AI_hub\\\\lip_J_1_F_04_C254_C_007.json',\n",
       " 'E:\\\\alpaco\\\\data\\\\AI_hub\\\\lip_J_1_F_04_C254_F_006.json',\n",
       " 'E:\\\\alpaco\\\\data\\\\AI_hub\\\\lip_J_1_F_04_C260_A_010.json',\n",
       " 'E:\\\\alpaco\\\\data\\\\AI_hub\\\\lip_J_1_F_04_C260_C_002.json',\n",
       " 'E:\\\\alpaco\\\\data\\\\AI_hub\\\\lip_J_1_F_04_C260_G_001.json',\n",
       " 'E:\\\\alpaco\\\\data\\\\AI_hub\\\\lip_J_1_F_04_C263_A_004.json',\n",
       " 'E:\\\\alpaco\\\\data\\\\AI_hub\\\\lip_J_1_F_04_C263_C_012.json',\n",
       " 'E:\\\\alpaco\\\\data\\\\AI_hub\\\\lip_J_1_F_04_C263_G_011.json',\n",
       " 'E:\\\\alpaco\\\\data\\\\AI_hub\\\\lip_J_1_F_04_C276_A_009.json',\n",
       " 'E:\\\\alpaco\\\\data\\\\AI_hub\\\\lip_J_1_F_04_C276_C_005.json',\n",
       " 'E:\\\\alpaco\\\\data\\\\AI_hub\\\\lip_J_1_F_04_C276_G_006.json',\n",
       " 'E:\\\\alpaco\\\\data\\\\AI_hub\\\\lip_J_1_F_04_C279_A_008.json',\n",
       " 'E:\\\\alpaco\\\\data\\\\AI_hub\\\\lip_J_1_F_04_C279_C_006.json',\n",
       " 'E:\\\\alpaco\\\\data\\\\AI_hub\\\\lip_J_1_F_04_C279_G_005.json',\n",
       " 'E:\\\\alpaco\\\\data\\\\AI_hub\\\\lip_J_1_F_04_C287_A_012.json',\n",
       " 'E:\\\\alpaco\\\\data\\\\AI_hub\\\\lip_J_1_F_04_C287_C_005.json',\n",
       " 'E:\\\\alpaco\\\\data\\\\AI_hub\\\\lip_J_1_F_04_C287_G_004.json',\n",
       " 'E:\\\\alpaco\\\\data\\\\AI_hub\\\\lip_J_1_F_04_C298_A_010.json',\n",
       " 'E:\\\\alpaco\\\\data\\\\AI_hub\\\\lip_J_1_F_04_C298_C_003.json',\n",
       " 'E:\\\\alpaco\\\\data\\\\AI_hub\\\\lip_J_1_F_04_C298_G_001.json',\n",
       " 'E:\\\\alpaco\\\\data\\\\AI_hub\\\\lip_J_1_F_04_C299_A_011.json',\n",
       " 'E:\\\\alpaco\\\\data\\\\AI_hub\\\\lip_J_1_F_04_C299_C_006.json',\n",
       " 'E:\\\\alpaco\\\\data\\\\AI_hub\\\\lip_J_1_F_04_C299_G_002.json',\n",
       " 'E:\\\\alpaco\\\\data\\\\AI_hub\\\\lip_J_1_F_04_C300_A_007.json',\n",
       " 'E:\\\\alpaco\\\\data\\\\AI_hub\\\\lip_J_1_F_04_C300_C_008.json',\n",
       " 'E:\\\\alpaco\\\\data\\\\AI_hub\\\\lip_J_1_F_04_C300_G_009.json',\n",
       " 'E:\\\\alpaco\\\\data\\\\AI_hub\\\\lip_J_1_F_04_C309_A_012.json',\n",
       " 'E:\\\\alpaco\\\\data\\\\AI_hub\\\\lip_J_1_F_04_C309_C_011.json',\n",
       " 'E:\\\\alpaco\\\\data\\\\AI_hub\\\\lip_J_1_F_04_C309_G_010.json']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_save_path = 'E:\\\\alpaco\\\\data'     # makeittalk, w2l 데이터 셋 저장 경로\n",
    "\n",
    "w2l_path = os.path.join(base_save_path, 'W2L')\n",
    "mit_path = os.path.join(base_save_path, 'MIT')\n",
    "\n",
    "if not os.path.exists(w2l_path):\n",
    "    os.mkdir(w2l_path)\n",
    "if not os.path.exists(mit_path):\n",
    "    os.mkdir(mit_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['E:\\\\alpaco\\\\data\\\\AI_hub\\\\lip_J_1_F_04_C190_C_005.json',\n",
       " 'E:\\\\alpaco\\\\data\\\\AI_hub\\\\lip_J_1_F_04_C190_G_006.json',\n",
       " 'E:\\\\alpaco\\\\data\\\\AI_hub\\\\lip_J_1_F_04_C210_A_010.json',\n",
       " 'E:\\\\alpaco\\\\data\\\\AI_hub\\\\lip_J_1_F_04_C210_C_003.json']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_paths[1:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['E:\\\\alpaco\\\\data\\\\AI_hub\\\\lip_J_1_F_04_C190_C_005.mp4',\n",
       " 'E:\\\\alpaco\\\\data\\\\AI_hub\\\\lip_J_1_F_04_C190_G_006.mp4',\n",
       " 'E:\\\\alpaco\\\\data\\\\AI_hub\\\\lip_J_1_F_04_C210_A_010.mp4',\n",
       " 'E:\\\\alpaco\\\\data\\\\AI_hub\\\\lip_J_1_F_04_C210_C_003.mp4']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_paths[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_idx = 178\n",
    "\n",
    "for folder_idx, (v_p, j_p) in enumerate(zip(video_paths[start_idx:], json_paths[start_idx:])):                  ### 중간에 오류나거나 끊겨서 다시 해야하면 여기 수정해서 이미 했던 것 넘기고 하고\n",
    "    fps_29_to_25(v_p)     # 5분 짜리 30프레임 -> 25프레임(약 17분 걸림) \n",
    "    print(folder_idx+1)\n",
    "    # 나머지 과정은 7분정도 걸림\n",
    "    frame_data = make_frame_dataset(j_p)\n",
    "    v_p = v_p.replace('.mp4', '_25fps.mp4')\n",
    "    \n",
    "    folder_idx += start_idx+1                                                                       ### 여기 폴더 인덱스 잘 수정해서 해야 이미 했던 폴더이름 안겹치게 해서 \n",
    "    \n",
    "    if not os.path.exists(os.path.join(w2l_path, f'{folder_idx:03d}')):                 \n",
    "        os.makedirs(os.path.join(w2l_path, f'{folder_idx:03d}'))\n",
    "    if not os.path.exists(os.path.join(mit_path, f'{folder_idx:03d}')):\n",
    "        os.makedirs(os.path.join(mit_path, f'{folder_idx:03d}'))\n",
    "\n",
    "    for file_idx, (s, e, text) in enumerate(frame_data):           \n",
    "        file_idx+=1\n",
    "\n",
    "        w2l_save_path = os.path.join(w2l_path, f'{folder_idx:03d}', f'{file_idx:05d}')       ### 여기 밑에들 폴더 이름 잘 수정해서 해야 이미 했던 폴더에 안 덮어씌워짐\n",
    "\n",
    "        video_save_path = os.path.join(mit_path, f'{folder_idx:03d}', f'{file_idx:05d}.mp4')\n",
    "        audio_save_path = os.path.join(mit_path, f'{folder_idx:03d}', f'{file_idx:05d}.wav')\n",
    "\n",
    "        cut_video_audio(v_p, s, e, video_save_path, audio_save_path)\n",
    "        \n",
    "        combine_vid_aud(video_save_path, audio_save_path, w2l_save_path+'.mp4')\n",
    "        with open(w2l_save_path+'.txt', 'wt') as f: \n",
    "            f.write(f'''Text : {text.rstrip('.')}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "print('hello world')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\alpaco\\data\\MIT\\078_00001.txt\n",
      "video_dir : E:\\alpaco\\data\\MIT\\078\\00001.mp4\n",
      "Process Video E:\\alpaco\\data\\MIT\\078\\00001.mp4, len: 185, FPS: 25.00, W X H: 1080 x 720\n",
      "\t ==> Final processed frames 185/185\n"
     ]
    }
   ],
   "source": [
    "def convert(video_dir, out_dir, max_num_frames=2000):\n",
    "    ret, fl2d, fl3d = __video_facial_landmark_detection__(video_dir= video_dir, display=False, max_num_frames=max_num_frames)\n",
    "    if (not ret):\n",
    "        return\n",
    "    if (len(fl3d) < 9):\n",
    "        print('The length of the landmark is too short, skip')\n",
    "        return\n",
    "\n",
    "    # Step 3: raw save landmark / audio\n",
    "    fl3d = np.array(fl3d)\n",
    "    np.savetxt(out_dir,\n",
    "                fl3d, fmt='%.2f')\n",
    "\n",
    "base = r'E:\\alpaco\\data\\MIT\\078'\n",
    "for video in os.listdir(base):\n",
    "    if video[-3:] == 'mp4':\n",
    "        video_dir = os.path.join(base, video)\n",
    "        out_dir = base + '_' + video[:-3] + 'txt'\n",
    "        # print(out_dir)\n",
    "        convert(video_dir, out_dir)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def __video_facial_landmark_detection__(video_dir=None, display=False, WriteFileName='_fl_detect.mp4',\n",
    "                                        max_num_frames=250, write=False):\n",
    "\n",
    "    # load video\n",
    "    print('video_dir : ' + video_dir)\n",
    "    video = cv2.VideoCapture(video_dir)\n",
    "\n",
    "    # return false if cannot open\n",
    "    if (video.isOpened() == False):\n",
    "        print('Unable to open video file')\n",
    "        return False, None\n",
    "\n",
    "    # display info\n",
    "    length = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = video.get(cv2.CAP_PROP_FPS)\n",
    "    w = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    h = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    print('Process Video {}, len: {}, FPS: {:.2f}, W X H: {} x {}'.format(video_dir, length, fps, w, h))\n",
    "\n",
    "    video_facial_landmark = []  # face-landmark np array per frame =: idx + [x,y] * 68\n",
    "    video_facial_landmark_3d = []  # face-landmark np array per frame =: idx + [x,y,z] * 68\n",
    "    frame_id = 0\n",
    "    not_detected_frames = 0\n",
    "\n",
    "    # gpu_frame = cv2.cuda_GpuMat()   # gpu\n",
    "\n",
    "\n",
    "    while (video.isOpened()):\n",
    "        ret, frame = video.read()\n",
    "\n",
    "        # gpu_frame.upload(frame)  # gpu\n",
    "\n",
    "\n",
    "        # reach EOF\n",
    "        if (ret == False):\n",
    "            break\n",
    "\n",
    "        # too many not-detected frames (in middle of video)\n",
    "        if (not_detected_frames > 5):\n",
    "            if (len(video_facial_landmark) < 10):\n",
    "                # at beginning of the video\n",
    "                video_facial_landmark = []\n",
    "                video_facial_landmark_3d = []\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        # dlib facial landmark detect\n",
    "        \n",
    "        # img_ret, shape, shape_3d = __image_facial_landmark_detection__(img=gpu_frame)   # gpu\n",
    "        img_ret, shape, shape_3d = __image_facial_landmark_detection__(img=frame)   # cpu\n",
    "\n",
    "        # successfully detected\n",
    "        if (img_ret):\n",
    "            # print('\\t ==> frame {}/{}'.format(frame_id, length))\n",
    "\n",
    "            # current frame xy coordinates\n",
    "            xys = []\n",
    "            for part_i in range(68):\n",
    "                xys.append(shape.part(part_i).x)\n",
    "                xys.append(shape.part(part_i).y)\n",
    "\n",
    "            # check any not_detected_frames, and interp them\n",
    "            if (not_detected_frames > 0 and len(video_facial_landmark) > 0):\n",
    "                # interpolate\n",
    "                def interp(last, cur, num, dims=68 * 2 + 1):\n",
    "                    interp_xys_np = np.zeros((num, dims))\n",
    "                    for dim in range(dims):\n",
    "                        interp_xys_np[:, dim] = np.interp(np.arange(0, num), [-1, num], [last[dim], cur[dim]])\n",
    "                    interp_xys_np = np.round(interp_xys_np).astype('int')\n",
    "                    interp_xys = [list(xy) for xy in interp_xys_np]\n",
    "                    return interp_xys\n",
    "\n",
    "                interp_xys = interp(video_facial_landmark[-1], [frame_id] + xys, not_detected_frames)\n",
    "                video_facial_landmark += interp_xys\n",
    "\n",
    "            not_detected_frames = 0\n",
    "\n",
    "            # save landmark/frame_index\n",
    "            video_facial_landmark.append([frame_id] + xys)\n",
    "            if (shape_3d.any()):\n",
    "                video_facial_landmark_3d.append([frame_id] + list(np.reshape(shape_3d, -1)))\n",
    "\n",
    "\n",
    "        else:\n",
    "            print('\\t ==> frame {}/{} Not detected'.format(frame_id, length))\n",
    "            not_detected_frames += 1\n",
    "        \n",
    "        frame_id += 1\n",
    "\n",
    "        if(frame_id > max_num_frames):\n",
    "            break\n",
    "\n",
    "    video.release()\n",
    " \n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    print('\\t ==> Final processed frames {}/{}'.format(frame_id, length))\n",
    "\n",
    "    return True, video_facial_landmark, video_facial_landmark_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting face_alignment\n",
      "  Downloading face_alignment-1.3.5.tar.gz (27 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: torch in d:\\alpaco\\vscode\\testenv\\lib\\site-packages (from face_alignment) (1.12.1+cu116)\n",
      "Requirement already satisfied: numpy in d:\\alpaco\\vscode\\testenv\\lib\\site-packages (from face_alignment) (1.24.2)\n",
      "Requirement already satisfied: scipy>=0.17 in d:\\alpaco\\vscode\\testenv\\lib\\site-packages (from face_alignment) (1.10.1)\n",
      "Collecting scikit-image (from face_alignment)\n",
      "  Downloading scikit_image-0.20.0-cp310-cp310-win_amd64.whl (23.7 MB)\n",
      "                                              0.0/23.7 MB ? eta -:--:--\n",
      "                                              0.5/23.7 MB 15.5 MB/s eta 0:00:02\n",
      "     -                                        1.0/23.7 MB 12.9 MB/s eta 0:00:02\n",
      "     --                                       1.6/23.7 MB 12.4 MB/s eta 0:00:02\n",
      "     ---                                      2.1/23.7 MB 12.1 MB/s eta 0:00:02\n",
      "     ----                                     2.6/23.7 MB 12.9 MB/s eta 0:00:02\n",
      "     -----                                    3.1/23.7 MB 12.5 MB/s eta 0:00:02\n",
      "     ------                                   3.7/23.7 MB 12.4 MB/s eta 0:00:02\n",
      "     -------                                  4.2/23.7 MB 12.3 MB/s eta 0:00:02\n",
      "     --------                                 4.8/23.7 MB 12.1 MB/s eta 0:00:02\n",
      "     --------                                 5.3/23.7 MB 12.1 MB/s eta 0:00:02\n",
      "     ---------                                5.8/23.7 MB 12.0 MB/s eta 0:00:02\n",
      "     ----------                               6.4/23.7 MB 12.0 MB/s eta 0:00:02\n",
      "     -----------                              6.9/23.7 MB 11.9 MB/s eta 0:00:02\n",
      "     ------------                             7.4/23.7 MB 11.9 MB/s eta 0:00:02\n",
      "     -------------                            8.0/23.7 MB 12.1 MB/s eta 0:00:02\n",
      "     --------------                           8.5/23.7 MB 12.1 MB/s eta 0:00:02\n",
      "     ---------------                          9.0/23.7 MB 12.0 MB/s eta 0:00:02\n",
      "     ----------------                         9.6/23.7 MB 12.0 MB/s eta 0:00:02\n",
      "     ----------------                        10.1/23.7 MB 11.9 MB/s eta 0:00:02\n",
      "     -----------------                       10.6/23.7 MB 11.7 MB/s eta 0:00:02\n",
      "     ------------------                      11.2/23.7 MB 11.7 MB/s eta 0:00:02\n",
      "     -------------------                     11.7/23.7 MB 11.7 MB/s eta 0:00:02\n",
      "     --------------------                    12.2/23.7 MB 11.7 MB/s eta 0:00:01\n",
      "     --------------------                    12.6/23.7 MB 11.9 MB/s eta 0:00:01\n",
      "     --------------------                    12.6/23.7 MB 11.9 MB/s eta 0:00:01\n",
      "     --------------------                    12.6/23.7 MB 11.9 MB/s eta 0:00:01\n",
      "     --------------------                    12.6/23.7 MB 11.9 MB/s eta 0:00:01\n",
      "     --------------------                    12.6/23.7 MB 11.9 MB/s eta 0:00:01\n",
      "     --------------------                    12.6/23.7 MB 11.9 MB/s eta 0:00:01\n",
      "     ----------------------                   13.1/23.7 MB 9.2 MB/s eta 0:00:02\n",
      "     -----------------------                  13.6/23.7 MB 9.2 MB/s eta 0:00:02\n",
      "     -----------------------                  14.2/23.7 MB 9.2 MB/s eta 0:00:02\n",
      "     ------------------------                 14.7/23.7 MB 9.2 MB/s eta 0:00:01\n",
      "     -------------------------                15.2/23.7 MB 9.2 MB/s eta 0:00:01\n",
      "     --------------------------               15.8/23.7 MB 9.4 MB/s eta 0:00:01\n",
      "     ---------------------------              16.3/23.7 MB 9.2 MB/s eta 0:00:01\n",
      "     ----------------------------             16.8/23.7 MB 9.2 MB/s eta 0:00:01\n",
      "     -----------------------------            17.4/23.7 MB 9.2 MB/s eta 0:00:01\n",
      "     ------------------------------           17.9/23.7 MB 9.2 MB/s eta 0:00:01\n",
      "     -------------------------------          18.4/23.7 MB 9.2 MB/s eta 0:00:01\n",
      "     -------------------------------          18.9/23.7 MB 9.2 MB/s eta 0:00:01\n",
      "     --------------------------------         19.5/23.7 MB 9.2 MB/s eta 0:00:01\n",
      "     ---------------------------------        20.0/23.7 MB 9.2 MB/s eta 0:00:01\n",
      "     ----------------------------------       20.6/23.7 MB 9.2 MB/s eta 0:00:01\n",
      "     -----------------------------------      21.0/23.7 MB 9.2 MB/s eta 0:00:01\n",
      "     ------------------------------------     21.6/23.7 MB 9.2 MB/s eta 0:00:01\n",
      "     -------------------------------------    22.1/23.7 MB 9.2 MB/s eta 0:00:01\n",
      "     --------------------------------------   22.7/23.7 MB 9.2 MB/s eta 0:00:01\n",
      "     --------------------------------------  23.2/23.7 MB 11.7 MB/s eta 0:00:01\n",
      "     --------------------------------------  23.7/23.7 MB 11.9 MB/s eta 0:00:01\n",
      "     --------------------------------------- 23.7/23.7 MB 11.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: opencv-python in d:\\alpaco\\vscode\\testenv\\lib\\site-packages (from face_alignment) (4.7.0.72)\n",
      "Requirement already satisfied: tqdm in d:\\alpaco\\vscode\\testenv\\lib\\site-packages (from face_alignment) (4.65.0)\n",
      "Collecting numba (from face_alignment)\n",
      "  Downloading numba-0.57.0-cp310-cp310-win_amd64.whl (2.6 MB)\n",
      "                                              0.0/2.6 MB ? eta -:--:--\n",
      "     --------                                 0.6/2.6 MB 12.2 MB/s eta 0:00:01\n",
      "     -----------------                        1.1/2.6 MB 11.8 MB/s eta 0:00:01\n",
      "     -------------------------                1.6/2.6 MB 11.6 MB/s eta 0:00:01\n",
      "     ---------------------------------        2.2/2.6 MB 11.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 2.6/2.6 MB 11.7 MB/s eta 0:00:00\n",
      "Collecting llvmlite<0.41,>=0.40.0dev0 (from numba->face_alignment)\n",
      "  Downloading llvmlite-0.40.0-cp310-cp310-win_amd64.whl (27.7 MB)\n",
      "                                              0.0/27.7 MB ? eta -:--:--\n",
      "                                              0.6/27.7 MB 11.5 MB/s eta 0:00:03\n",
      "     -                                        1.1/27.7 MB 11.3 MB/s eta 0:00:03\n",
      "     --                                       1.6/27.7 MB 11.3 MB/s eta 0:00:03\n",
      "     ---                                      2.1/27.7 MB 11.3 MB/s eta 0:00:03\n",
      "     ---                                      2.7/27.7 MB 11.3 MB/s eta 0:00:03\n",
      "     ----                                     3.2/27.7 MB 11.4 MB/s eta 0:00:03\n",
      "     -----                                    3.7/27.7 MB 11.4 MB/s eta 0:00:03\n",
      "     ------                                   4.3/27.7 MB 11.4 MB/s eta 0:00:03\n",
      "     ------                                   4.8/27.7 MB 11.4 MB/s eta 0:00:03\n",
      "     -------                                  5.4/27.7 MB 11.8 MB/s eta 0:00:02\n",
      "     --------                                 5.9/27.7 MB 11.7 MB/s eta 0:00:02\n",
      "     ---------                                6.4/27.7 MB 11.7 MB/s eta 0:00:02\n",
      "     ----------                               6.9/27.7 MB 11.7 MB/s eta 0:00:02\n",
      "     ----------                               7.5/27.7 MB 11.6 MB/s eta 0:00:02\n",
      "     -----------                              8.0/27.7 MB 11.6 MB/s eta 0:00:02\n",
      "     ------------                             8.6/27.7 MB 11.6 MB/s eta 0:00:02\n",
      "     -------------                            9.1/27.7 MB 11.6 MB/s eta 0:00:02\n",
      "     -------------                            9.6/27.7 MB 11.8 MB/s eta 0:00:02\n",
      "     --------------                          10.1/27.7 MB 11.8 MB/s eta 0:00:02\n",
      "     ---------------                         10.7/27.7 MB 11.9 MB/s eta 0:00:02\n",
      "     ---------------                         11.2/27.7 MB 11.9 MB/s eta 0:00:02\n",
      "     ----------------                        11.7/27.7 MB 11.9 MB/s eta 0:00:02\n",
      "     -----------------                       12.3/27.7 MB 11.9 MB/s eta 0:00:02\n",
      "     ------------------                      12.8/27.7 MB 11.7 MB/s eta 0:00:02\n",
      "     ------------------                      13.4/27.7 MB 11.7 MB/s eta 0:00:02\n",
      "     -------------------                     13.9/27.7 MB 11.7 MB/s eta 0:00:02\n",
      "     --------------------                    14.4/27.7 MB 11.7 MB/s eta 0:00:02\n",
      "     ---------------------                   15.0/27.7 MB 11.9 MB/s eta 0:00:02\n",
      "     ---------------------                   15.5/27.7 MB 11.9 MB/s eta 0:00:02\n",
      "     ----------------------                  16.0/27.7 MB 11.9 MB/s eta 0:00:01\n",
      "     -----------------------                 16.5/27.7 MB 11.9 MB/s eta 0:00:01\n",
      "     ------------------------                17.1/27.7 MB 11.7 MB/s eta 0:00:01\n",
      "     ------------------------                17.6/27.7 MB 11.7 MB/s eta 0:00:01\n",
      "     -------------------------               18.1/27.7 MB 11.7 MB/s eta 0:00:01\n",
      "     --------------------------              18.7/27.7 MB 11.7 MB/s eta 0:00:01\n",
      "     --------------------------              18.9/27.7 MB 11.7 MB/s eta 0:00:01\n",
      "     --------------------------              19.2/27.7 MB 11.3 MB/s eta 0:00:01\n",
      "     ---------------------------             19.7/27.7 MB 11.3 MB/s eta 0:00:01\n",
      "     ----------------------------            20.2/27.7 MB 11.3 MB/s eta 0:00:01\n",
      "     -----------------------------           20.8/27.7 MB 11.3 MB/s eta 0:00:01\n",
      "     -----------------------------           21.3/27.7 MB 11.1 MB/s eta 0:00:01\n",
      "     ------------------------------          21.8/27.7 MB 11.1 MB/s eta 0:00:01\n",
      "     -------------------------------         22.4/27.7 MB 11.1 MB/s eta 0:00:01\n",
      "     --------------------------------        22.9/27.7 MB 11.1 MB/s eta 0:00:01\n",
      "     ---------------------------------       23.4/27.7 MB 11.1 MB/s eta 0:00:01\n",
      "     ---------------------------------       24.0/27.7 MB 11.3 MB/s eta 0:00:01\n",
      "     ----------------------------------      24.5/27.7 MB 11.3 MB/s eta 0:00:01\n",
      "     -----------------------------------     25.0/27.7 MB 11.3 MB/s eta 0:00:01\n",
      "     -----------------------------------     25.5/27.7 MB 11.1 MB/s eta 0:00:01\n",
      "     ------------------------------------    26.1/27.7 MB 11.1 MB/s eta 0:00:01\n",
      "     -------------------------------------   26.6/27.7 MB 11.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  27.1/27.7 MB 11.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  27.7/27.7 MB 11.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  27.7/27.7 MB 11.1 MB/s eta 0:00:01\n",
      "     --------------------------------------- 27.7/27.7 MB 10.5 MB/s eta 0:00:00\n",
      "Collecting networkx>=2.8 (from scikit-image->face_alignment)\n",
      "  Downloading networkx-3.1-py3-none-any.whl (2.1 MB)\n",
      "                                              0.0/2.1 MB ? eta -:--:--\n",
      "     --------                                 0.4/2.1 MB 13.9 MB/s eta 0:00:01\n",
      "     ------------------                       1.0/2.1 MB 12.3 MB/s eta 0:00:01\n",
      "     ----------------------------             1.5/2.1 MB 11.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.0/2.1 MB 11.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 2.1/2.1 MB 11.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pillow>=9.0.1 in d:\\alpaco\\vscode\\testenv\\lib\\site-packages (from scikit-image->face_alignment) (9.4.0)\n",
      "Requirement already satisfied: imageio>=2.4.1 in d:\\alpaco\\vscode\\testenv\\lib\\site-packages (from scikit-image->face_alignment) (2.27.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in d:\\alpaco\\vscode\\testenv\\lib\\site-packages (from scikit-image->face_alignment) (2023.4.12)\n",
      "Collecting PyWavelets>=1.1.1 (from scikit-image->face_alignment)\n",
      "  Downloading PyWavelets-1.4.1-cp310-cp310-win_amd64.whl (4.2 MB)\n",
      "                                              0.0/4.2 MB ? eta -:--:--\n",
      "     -----                                    0.6/4.2 MB 11.5 MB/s eta 0:00:01\n",
      "     ----------                               1.1/4.2 MB 11.4 MB/s eta 0:00:01\n",
      "     ---------------                          1.6/4.2 MB 11.5 MB/s eta 0:00:01\n",
      "     --------------------                     2.2/4.2 MB 12.4 MB/s eta 0:00:01\n",
      "     -------------------------                2.7/4.2 MB 12.2 MB/s eta 0:00:01\n",
      "     ------------------------------           3.2/4.2 MB 12.0 MB/s eta 0:00:01\n",
      "     ------------------------------------     3.7/4.2 MB 12.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  4.2/4.2 MB 12.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 4.2/4.2 MB 11.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\alpaco\\vscode\\testenv\\lib\\site-packages (from scikit-image->face_alignment) (23.0)\n",
      "Collecting lazy_loader>=0.1 (from scikit-image->face_alignment)\n",
      "  Downloading lazy_loader-0.2-py3-none-any.whl (8.6 kB)\n",
      "Requirement already satisfied: typing-extensions in d:\\alpaco\\vscode\\testenv\\lib\\site-packages (from torch->face_alignment) (4.5.0)\n",
      "Requirement already satisfied: colorama in d:\\alpaco\\vscode\\testenv\\lib\\site-packages (from tqdm->face_alignment) (0.4.6)\n",
      "Building wheels for collected packages: face_alignment\n",
      "  Building wheel for face_alignment (setup.py): started\n",
      "  Building wheel for face_alignment (setup.py): finished with status 'done'\n",
      "  Created wheel for face_alignment: filename=face_alignment-1.3.5-py2.py3-none-any.whl size=28260 sha256=76002590544d9f2c10869c5946f0f3efcec249593bd75c45585b309af36a7b3b\n",
      "  Stored in directory: c:\\users\\ayun3\\appdata\\local\\pip\\cache\\wheels\\97\\4f\\65\\48940e0c8eabe818a5170a1117777520718d5a875a25626789\n",
      "Successfully built face_alignment\n",
      "Installing collected packages: PyWavelets, networkx, llvmlite, lazy_loader, scikit-image, numba, face_alignment\n",
      "Successfully installed PyWavelets-1.4.1 face_alignment-1.3.5 lazy_loader-0.2 llvmlite-0.40.0 networkx-3.1 numba-0.57.0 scikit-image-0.20.0\n",
      "Requirement already satisfied: face_alignment in d:\\alpaco\\vscode\\testenv\\lib\\site-packages (1.3.5)\n",
      "Requirement already satisfied: torch in d:\\alpaco\\vscode\\testenv\\lib\\site-packages (from face_alignment) (1.12.1+cu116)\n",
      "Requirement already satisfied: numpy in d:\\alpaco\\vscode\\testenv\\lib\\site-packages (from face_alignment) (1.24.2)\n",
      "Requirement already satisfied: scipy>=0.17 in d:\\alpaco\\vscode\\testenv\\lib\\site-packages (from face_alignment) (1.10.1)\n",
      "Requirement already satisfied: scikit-image in d:\\alpaco\\vscode\\testenv\\lib\\site-packages (from face_alignment) (0.20.0)\n",
      "Requirement already satisfied: opencv-python in d:\\alpaco\\vscode\\testenv\\lib\\site-packages (from face_alignment) (4.7.0.72)\n",
      "Requirement already satisfied: tqdm in d:\\alpaco\\vscode\\testenv\\lib\\site-packages (from face_alignment) (4.65.0)\n",
      "Requirement already satisfied: numba in d:\\alpaco\\vscode\\testenv\\lib\\site-packages (from face_alignment) (0.57.0)\n",
      "Requirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in d:\\alpaco\\vscode\\testenv\\lib\\site-packages (from numba->face_alignment) (0.40.0)\n",
      "Requirement already satisfied: networkx>=2.8 in d:\\alpaco\\vscode\\testenv\\lib\\site-packages (from scikit-image->face_alignment) (3.1)\n",
      "Requirement already satisfied: pillow>=9.0.1 in d:\\alpaco\\vscode\\testenv\\lib\\site-packages (from scikit-image->face_alignment) (9.4.0)\n",
      "Requirement already satisfied: imageio>=2.4.1 in d:\\alpaco\\vscode\\testenv\\lib\\site-packages (from scikit-image->face_alignment) (2.27.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in d:\\alpaco\\vscode\\testenv\\lib\\site-packages (from scikit-image->face_alignment) (2023.4.12)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in d:\\alpaco\\vscode\\testenv\\lib\\site-packages (from scikit-image->face_alignment) (1.4.1)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\alpaco\\vscode\\testenv\\lib\\site-packages (from scikit-image->face_alignment) (23.0)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in d:\\alpaco\\vscode\\testenv\\lib\\site-packages (from scikit-image->face_alignment) (0.2)\n",
      "Requirement already satisfied: typing-extensions in d:\\alpaco\\vscode\\testenv\\lib\\site-packages (from torch->face_alignment) (4.5.0)\n",
      "Requirement already satisfied: colorama in d:\\alpaco\\vscode\\testenv\\lib\\site-packages (from tqdm->face_alignment) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "# !pip install face_alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_alignment\n",
    "\n",
    "predictor = face_alignment.FaceAlignment(face_alignment.LandmarksType._2D, device='cuda', flip_input=True)\n",
    "\n",
    "def __image_facial_landmark_detection__(img=None):\n",
    "        shapes = predictor.get_landmarks(img)\n",
    "        if (not shapes):\n",
    "            return False, None, None\n",
    "\n",
    "        max_size_idx = 0\n",
    "        shape = ShapeParts(shapes[max_size_idx][:, 0:2])\n",
    "        shape_3d = shapes[max_size_idx]\n",
    "\n",
    "        # when use 2d estimator\n",
    "        shape_3d = np.concatenate([shape_3d, np.ones(shape=(68, 1))], axis=1)\n",
    "\n",
    "        return True, shape, shape_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Point:\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "\n",
    "class ShapeParts:\n",
    "    def __init__(self, np_pts):\n",
    "        self.data = np_pts\n",
    "\n",
    "    def part(self, idx):\n",
    "        return Point(self.data[idx, 0], self.data[idx, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
