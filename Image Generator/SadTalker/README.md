<div align="center">

<img src='https://user-images.githubusercontent.com/4397546/229094115-862c747e-7397-4b54-ba4a-bd368bfe2e0f.png' width='500px'/>


<!--<h2> ğŸ˜­ SadTalkerï¼š <span style="font-size:12px">Learning Realistic 3D Motion Coefficients for Stylized Audio-Driven Single Image Talking Face Animation </span> </h2> -->

  <a href='https://arxiv.org/abs/2211.12194'><img src='https://img.shields.io/badge/ArXiv-PDF-red'></a> &nbsp; 
  <a href='https://sadtalker.github.io'><img src='https://img.shields.io/badge/SadTalker-Reference-Green'></a> &nbsp;
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Winfredy/SadTalker/blob/main/quick_demo.ipynb) &nbsp;

<img src="https://github.com/suted2/AI_video_chatbot/blob/dbf0733fe0cc80634c0aef0a8145c62829d75059/Image%20Generator/assets/KakaoTalk_20230626_174102381.gif" width="500" height="400"/>

<b>TL;DR: &nbsp;&nbsp;&nbsp;&nbsp; single image ğŸ™â€â™‚ï¸  &nbsp;&nbsp;&nbsp;&nbsp;+  &nbsp;&nbsp;&nbsp;&nbsp; audio ğŸ¤  &nbsp;&nbsp;&nbsp;&nbsp; =  &nbsp;&nbsp;&nbsp;&nbsp; talking head video ğŸ.</b>

<br>

</div>

# ğŸ“ 0. Paper

## Summary

1. ì–¼êµ´ í‘œì •ê³¼ ì–¼êµ´ ì›€ì§ì„ì˜ ë¶„ë¦¬
> ExpNet(ì–¼êµ´ì›€ì§ì„ ë° ì…ëª¨ì–‘) + PoseVAE(ë¨¸ë¦¬ ì›€ì§ì„)ìœ¼ë¡œ ëª¨ë“ˆì„ ë…ë¦½ì ìœ¼ë¡œ êµ¬ì„±í•˜ê³ , í•™ìŠµí•¨ìœ¼ë¡œì¨ ë…ë¦½ì ì¸ ìƒì„±ì„ í•˜ì—¬ ë” ìì—°ìŠ¤ëŸ¬ìš´ ì›€ì§ì„ ìƒì„±
2. ìŒì„± ë°ì´í„°ì˜ ë¶€ë¶„ì  ì‚¬ìš©
> ìŒì„± ë°ì´í„°ê°€ í•„ìš”í•œ ë¶€ë¶„ë§Œ (ExpNetì—ì„œëŠ” ì…ëª¨ì–‘, PoseVAEì—ì„œëŠ” identity style, rhythm) ë°ì´í„°ë¥¼ ì—°ê²°í•˜ê³ , ë‹¤ë¥¸ ì›€ì§ì„ë“¤ì€ ì†Œë¦¬ì™€ ê´€ê³„ì—†ì´ ëœë¤ì ìœ¼ë¡œ ìƒì„±í•˜ê²Œ ì„¤ê³„

## Main Pipeline
![main pipeline](docs/main_pipeline.PNG)


1. image inputì„ coefficients of 3DMM(3D Morphable Model)ë¡œ ì²« ì´ë¯¸ì§€ì˜ facial expression($\beta_{0}$), head pose($\rho_{0}$)ë¥¼ ìƒì„±í•œë‹¤.
2. audio feature input($\alpha_{\{1...n\}}$)ì™€ $\beta_{0}$ë¥¼ ExpNetì— í†µê³¼ì‹œì¼œ ëˆˆê¹œë¹¡ì„, ì…ìˆ ëª¨ì–‘, ì–¼êµ´ í‘œì • ê°œì„ ì— ê´€í•œ ì—°ì†ê°’ì„ ì¶”ì¶œí•œë‹¤.($\beta_{\{1...n\}}$)
3. $\alpha_{\{1...n\}}$ì™€ $\rho_{0}$ë¥¼ PoseVAEì— í†µê³¼ì‹œì¼œ Styleì„ ì…íŒ ì—°ì†ê°’ì„ ì¶”ì¶œí•œë‹¤.($\rho_{\{1...n\}}$)
4. $\beta_{\{0...n\}}$ì™€ $\rho_{\{0...n\}}$ì„ 3D-Aware Face Render ëª¨ë“ˆì„ í†µí•´ ì—°ì†ì ì¸ Frameì„ ìƒì„±í•œë‹¤.

## Change Wav2Lip
![ExpNet](docs/ExpNet.png)
1. ExpNetì—ì„œ Wav2Lip ëª¨ë“ˆì„ ì´ìš©í•´ ì…ëª¨ì–‘ì„ ìƒì„±í•œë‹¤.
2. í•™ìŠµí•  ë•Œ Wav2Lip ëª¨ë“ˆì˜ weightë¥¼ ì ê·¸ê³  distillationì„ ì§„í–‰í•œë‹¤.
3. ê·¸ ë’¤ Testë¥¼ í•  ë•Œ ê·¸ë¦¼ì˜ ìœ„ìª½ ë¶€ë¶„ì„ ë–¼ì–´ ì‚¬ìš©í•œë‹¤.
> ì˜ì–´ë¡œ í•™ìŠµëœ Wav2Lip ëª¨ë“ˆì˜ ì˜¤ë””ì˜¤ ì¸ì½”ë”ë¥¼ ìš°ë¦¬ê°€ í•™ìŠµí•œ Wav2Lipì˜ ì˜¤ë””ì˜¤ ì¸ì½”ë”ë¡œ ë°”ê¾¸ëŠ” ë°©ë²•ì„ ìƒê°í–ˆë‹¤.

## Demo
| Source | ê¸°ì¡´ SadTalker | Ours SadTalker (with kor-wav2lip-ExpNet)
| :--- | :---------- | :---------- 
| ì§€ì°½ìš± ì†ŒìŠ¤ì´ë¯¸ì§€ | ì§€ì°½ìš± ë³€ê²½ì „ | ì§€ì°½ìš± ë³€ê²½í›„
| ìœ ì¬ì„ ì†ŒìŠ¤ì´ë¯¸ì§€ | ìœ ì¬ì„ ë³€ê²½ì „ | ìœ ì¬ì„ ë³€ê²½í›„

> ì…ëª¨ì–‘ì€ ì˜ ë§ê²Œ ëì§€ë§Œ ì–¼êµ´ style ìì²´ê°€ ë³€í˜•ëœë‹¤.

>> ë…¼ë¬¸ìƒì—ì„œ ë°íˆê¸¸ ì™¸êµ­ì¸ dataë¡œ í•™ìŠµì„ ì§„í–‰í–ˆê³ , í•™ìŠµ costê°€ ë§¤ìš° ë†’ì€ ê²ƒìœ¼ë¡œ í™•ì¸ë˜ì–´ ì…ëª¨ì–‘ ì™¸ì˜ ëª¨ë“ˆì€ íŠœë‹í•˜ê¸° ì–´ë ¤ìš¸ ê²ƒì´ë¼ íŒë‹¨í–ˆë‹¤. ì¶”í›„ dataì™€ í™˜ê²½ì´ ê°–ì¶°ì§€ë©´ í•´ê²° ê°€ëŠ¥í•´ ë³´ì¸ë‹¤.

# âš™ï¸ 1. Installation

## Windows:

1. [Python 3.10.6](https://www.python.org/downloads/windows/) ì„¤ì¹˜, python í™˜ê²½ë³€ìˆ˜ ì„¤ì • ì²´í¬í•˜ê¸°.
2. [git](https://git-scm.com/download/win) ì„¤ì¹˜
3. `ffmpeg` ì„¤ì¹˜, [ì—¬ê¸°](https://www.wikihow.com/Install-FFmpeg-on-Windows)ë¥¼ ì°¸ê³ í•´ ì„¤ì¹˜í•  ê²ƒ. (pip install ffmpegì€ ì•ˆë  ìˆ˜ ìˆìŒ).
4. commandì°½ì— `git clone https://github.com/Winfredy/SadTalker.git` ì…ë ¥.
5. [ì—¬ê¸°ì„œ](#ğŸ“¥-2-download-trained-models) `checkpoint`ë‘ `gfpgan`  ë‹¤ìš´ë¡œë“œ.

# ğŸ“¥ 2. Download Trained Models

**Google Driver**: [main checkpoints](https://drive.google.com/file/d/1gwWh45pF7aelNP_P78uDJL8Sycep-K7j/view?usp=sharing), [gfpgan](https://drive.google.com/file/d/19AIBsmfcHW6BRJmeqSFlG5fL445Xmsyi?usp=sharing)




Model explains:

| Model | Description
| :--- | :----------
|checkpoints/mapping_00229-model.pth.tar | Pre-trained MappingNet in Sadtalker.
|checkpoints/mapping_00109-model.pth.tar | Pre-trained MappingNet in Sadtalker.
|checkpoints/SadTalker_V0.0.2_256.safetensors | packaged sadtalker checkpoints of old version, 256 face render.
|checkpoints/SadTalker_V0.0.2_512.safetensors | packaged sadtalker checkpoints of old version, 512 face render.
|gfpgan/weights | Face detection and enhanced models used in `facexlib` and `gfpgan`.


# ğŸ”® 3. Quick Start

âš ï¸ reference githubì˜ quick_demo.ipynbëŠ” requirements.txt ë¬¸ì œë¡œ ì •ìƒ ì‹¤í–‰ì´ ì–´ë ¤ì›€ì„ í™•ì¸(~23.06.28)

1. conda ê°€ìƒí™˜ê²½ ì„¤ì¹˜
2. git clone
```command
conda create -n sad-talker python=3.10
git clone https://github.com/Winfredy/SadTalker.git
```
3. requirements ì„¤ì¹˜( 230628 ê¸°ì¤€ requirements)
```command
pip install -r requirements.txt
```
4. torch cuda11.7 ì„¤ì¹˜( 3070 Ti ê¸°ì¤€)

```command
conda install pytorch torchvision torchaudio pytorch-cuda=11.7 -c pytorch -c nvidia
```
5. Inference



```bash
python inference.py --driven_audio 0_0_00004.wav \ 
--source_image UJaeSuck1.mp4 \
--result_dir ./results \
--still \
--enhancer gfpgan \
--checkpoint_dir SadTalker \
--size 512
```
```bash
# driven_audio   : ë§Œë“¤ ì˜ìƒì˜ input wav      (default : ./examples/driven_audio/bus_chinese.wav)
# source_image   : ë§Œë“¤ ì˜ìƒì˜ image or video (default : ./examples/source_image/full_body_1.png)
# result_dir     : output í´ë”               (default : ./results)
# still          : ì–¼êµ´ë§Œ cropí•˜ëŠ” ì˜µì…˜
# enhancer       : ì–¼êµ´ ë” ìì—°ìŠ¤ëŸ½ê²Œ í›„ì²˜ë¦¬   (default : None)
# checkpoint_dir : ëª¨ë¸ checkpoint í´ë”       (default : ./checkpoints) 
# size           : facerender size           (default : 256)
```
ë‹¤ë¥¸ ì˜µì…˜ë“¤ì€ inference.pyì— ëª…ì‹œë˜ì–´ ìˆìŠµë‹ˆë‹¤.
# ğŸ› Citation
If you find our work useful in your research, please consider citing:

```bibtex
@article{zhang2022sadtalker,
  title={SadTalker: Learning Realistic 3D Motion Coefficients for Stylized Audio-Driven Single Image Talking Face Animation},
  author={Zhang, Wenxuan and Cun, Xiaodong and Wang, Xuan and Zhang, Yong and Shen, Xi and Guo, Yu and Shan, Ying and Wang, Fei},
  journal={arXiv preprint arXiv:2211.12194},
  year={2022}
}
```


